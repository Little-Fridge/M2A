from dataclasses import dataclass, field, asdict
import json
import os
from typing import Any, Optional, Literal

import numpy as np
from pymilvus import AnnSearchRequest, DataType, Function, FunctionType, MilvusClient, RRFRanker

from ..embeddings.text import TextEmbedding
from ..embeddings.multimodal import MultimodalEmbedder

from ..config import TextEmbeddingConfig, MultimodalEmbeddingConfig

@dataclass
class SemanticMemory:
    """High-level semantic observation (Layer 2)"""
    memory_id: Optional[int] = None
    text: Optional[str] = None
    image_caption: Optional[str] = None  # Generated caption for images
    image_path: Optional[str] = None
    evidence_ids: list[list[int]] = field(default_factory=list)  # [[start,end], ...]

class SemanticStore:
    def __init__(
        self,
        db_path: str = "semantic_store.db",
        re_use: bool = False,
        text_embedder_config: Optional[TextEmbedding] = None,
        multimodal_embedder_config: Optional[MultimodalEmbeddingConfig] = None,
    ):
        if not re_use and os.path.exists(db_path):
            print(f"Remove existing semantic db: {db_path}")
            os.remove(db_path)

        if os.path.dirname(db_path) and not os.path.exists(os.path.dirname(db_path)):
            os.makedirs(os.path.dirname(db_path))

        self.db = MilvusClient(db_path)
        
        if not text_embedder_config:
            text_embedder_config = TextEmbeddingConfig()
        if not multimodal_embedder_config:
            multimodal_embedder_config = MultimodalEmbeddingConfig()

        self.text_embedder = TextEmbedding(**asdict(text_embedder_config))

        self.multimodal_embedder = MultimodalEmbedder(**asdict(multimodal_embedder_config))

        self.log = []
        self._init_db()

    def dump_db(self, path: str):
        res = self.db.query("memory", limit=16000)
        with open(path, 'w') as f:
            json.dump(res, f, indent=2)

        log_dir = os.path.dirname(path)
        log_path = os.path.join(log_dir, "semantic_log.json")
        with open(log_path, 'w') as f:
            json.dump(self.log, f, indent=2)

    def _init_db(self):
        db = self.db

        memory_schema = db.create_schema()

        # Add fields to schema
        memory_schema.add_field(field_name="id", datatype=DataType.INT64, is_primary=True, auto_id=True)
        memory_schema.add_field(field_name="text", datatype=DataType.VARCHAR, max_length=1000, enable_analyzer=True, description="memory text")
        memory_schema.add_field(field_name="image_caption", datatype=DataType.VARCHAR, max_length=1000, enable_analyzer=True, description="image caption")
        memory_schema.add_field(field_name="image_path", datatype=DataType.VARCHAR, max_length=100)
        memory_schema.add_field(field_name="evidence_ids", datatype=DataType.VARCHAR, max_length=1000, enable_analyzer=True)

        db.create_collection(
            collection_name="memory",
            schema=memory_schema,
        )

        # ====================================================

        text_embs_schema = db.create_schema()
        text_embs_schema.add_field(field_name="id", datatype=DataType.INT64, is_primary=True, )
        text_embs_schema.add_field(field_name="text", datatype=DataType.VARCHAR, max_length=1000, enable_analyzer=True, description="embed text")
        text_embs_schema.add_field(field_name="text_dense", datatype=DataType.FLOAT_VECTOR, dim=384, description="text dense embedding")
        text_embs_schema.add_field(field_name="text_sparse", datatype=DataType.SPARSE_FLOAT_VECTOR, description="text sparse embedding auto-generated by the built-in BM25 function")

        # Add function to schema
        bm25_function = Function(
            name="text_bm25_emb",
            input_field_names=["text"],
            output_field_names=["text_sparse"],
            function_type=FunctionType.BM25,
        )
        text_embs_schema.add_function(bm25_function)


        # Add indexes
        text_emb_index_params = db.prepare_index_params()
        text_emb_index_params.add_index(
            field_name="text_dense",
            index_name="text_dense_index",
            index_type="AUTOINDEX",
            metric_type="IP"
        )

        text_emb_index_params.add_index(
            field_name="text_sparse",
            index_name="text_sparse_index",
            index_type="SPARSE_INVERTED_INDEX",
            metric_type="IP",
            params={"inverted_index_algo": "DAAT_MAXSCORE"}, # or "DAAT_WAND" or "TAAT_NAIVE"
        )

        db.create_collection(
            "text_embs",
            schema=text_embs_schema,
            index_params=text_emb_index_params
        )

        # ====================================================
        image_embs_schema = db.create_schema()
        image_embs_schema.add_field(field_name="id", datatype=DataType.INT64, is_primary=True, )
        image_embs_schema.add_field(field_name="image_dense", datatype=DataType.FLOAT_VECTOR, dim=768, description="image dense embedding")

        image_embs_index_params = db.prepare_index_params()
        image_embs_index_params.add_index(
            field_name="image_dense",
            index_name="image_dense_index",
            index_type="AUTOINDEX",
            metric_type="IP"
        )

        db.create_collection(
            "image_embs",
            schema=image_embs_schema,
            index_params=image_embs_index_params
        )

    def close(self):
        self.db.close()

    def _get_memory_embed_text(self, text: Optional[str] = None, image_caption: Optional[str] = None) -> str:
        text_content = ""
        if text:
            text_content += text
        if image_caption:
            text_content += "\nWith image: " + image_caption
        return text_content.strip()

    def add(self, memory: SemanticMemory) -> str:
        """Add a new semantic memory"""

        # 1. add to memory
        memory_data = [{
            "text": memory.text,
            "image_caption": memory.image_caption or "",
            "image_path": memory.image_path or "",
            "evidence_ids": json.dumps(memory.evidence_ids)
        }]

        self.log.append({
            "op": "add",
            "data": memory_data
        })
        id = self.db.insert(
            collection_name="memory",
            data=memory_data
        )['ids'][0]

        # 2. add to text_embs
        # Generate text embedding (text + image_caption)
        text_content = self._get_memory_embed_text(memory.text, memory.image_caption)
        if text_content:
            text_vec = self._embed_text(text_content)

            text_embs_data = [{
                "id": id,
                "text": text_content,
                "text_dense": text_vec
            }]

            self.db.insert(
                collection_name="text_embs",
                data=text_embs_data
            )

        # 3. add to image_embs
        # Generate visual embedding if images exist
        if memory.image_path:
            # For prototype: use first image only
            # In production: aggregate multiple images or store separately
            image_vec = self._embed_image(memory.image_path)

            image_embs_data = [{
                "id": id,
                "image_dense": image_vec
            }]

            self.db.insert(
                collection_name="image_embs",
                data=image_embs_data
            )


        return id

    def update(self, memory_id: str, updates: dict[str, Any]) -> None:
        res = self.db.search(
            collection_name="semantic",
            anns_field="vector",
            ids=[memory_id],
            limit=1,
            search_params={"metric_type": "IP"}
        )
        try:
            current = res[0][0]
        except:
            raise Exception("Memory_id does not exist!")

        if "text" in updates:
            text_content = self._get_memory_embed_text(updates["text"], current["image_caption"])
            text_dense = self._embed_text(text_content)
            self.db.upsert(
                "semantic",
                data=[{
                    "id": memory_id,
                    "text": updates["text"],
                    "text_dense": text_dense
                }]
            )
        if "image_caption" in updates:
            text_content = self._get_memory_embed_text(current["text"], updates["image_caption"])
            text_dense = self._embed_text(text_content)
            self.db.upsert(
                "semantic",
                data=[{
                    "id": memory_id,
                    "image_caption": updates["image_caption"],
                    "text_dense": text_dense
                }]
            )
        if "evidence_ids" in updates:
            evidence_ids = current["evidence_ids"] + updates["evidence_ids"]
            self.db.upsert(
                "semantic",
                data=[{
                    "id": memory_id,
                    "evidence_ids": evidence_ids
                }]
            )

    def delete(self, memory_id: str) -> dict[str, int]:
        self.db.delete(
            collection_name="memory",
            ids=[int(memory_id)]
        )
        self.log.append({
            "op": "delete",
            "id": memory_id
        })
        self.db.delete("text_embs", [int(memory_id)])
        self.db.delete("image_embs", [int(memory_id)])

    def hybrid_search(
        self,
        query_text: Optional[str] = None,
        query_image_path: Optional[str] = None,
        top_k: int = 8
    ) -> list[SemanticMemory]:
        self.log.append({
            "op": "search",
            "query_text": query_text,
            "query_image_path": query_image_path,
        })
        text_res = []
        if query_text:
            query_dense_vector = self._embed_text(query_text)
            query_multimodal_vector = self._embed_text_for_cross_modal(query_text)

            # text semantic search (dense)
            search_param_1 = {
                "data": [query_dense_vector],
                "anns_field": "text_dense",
                "param": {"nprobe": 10},
                "limit": 5
            }
            request_1 = AnnSearchRequest(**search_param_1)

            # full-text search (sparse)
            search_param_2 = {
                "data": [query_text],
                "anns_field": "text_sparse",
                "param": {},
                "limit": 5
            }
            request_2 = AnnSearchRequest(**search_param_2)

            # text-to-image search (multimodal)
            search_param_3 = {
                "data": [query_multimodal_vector],
                "anns_field": "image_dense",
                "param": {"nprobe": 10},
                "limit": 5
            }
            request_3 = AnnSearchRequest(**search_param_3)

            text_reqs = [request_1, request_2]

            ranker = RRFRanker()
            res = self.db.hybrid_search(
                collection_name="text_embs",
                reqs=text_reqs,
                ranker=ranker,
                limit=5
            )
            for hits in res:
                for hit in hits:
                    text_res.append(hit)

        # =================
        image_res = []
        if query_image_path:
            query_image_emb = self._embed_image(query_image_path)
            res = self.db.search(
                collection_name="image_embs",
                anns_field="image_dense",
                data=[query_image_emb],
                limit=3,
                search_params={"metric_type": "IP"}
            )

            for hits in res:
                for hit in hits:
                    image_res.append(hit)

        hybrid_res = self._rrf([
            text_res,
            image_res
        ])

        return [
            self._get_memory_by_id(mem_id) # must fetch one at a time to ensure order
            for mem_id, score in hybrid_res
        ][:top_k]

    def _get_memory_by_id(self, id: int | str) -> SemanticMemory:
        id = int(id)
        res = self.db.get(
            collection_name="memory",
            ids=[id], # a list of primary keys
            limit=1,
        )[0]

        return SemanticMemory(
            memory_id=res['id'],
            text=res['text'],
            image_caption=res['image_caption'] if res['image_caption'] else None,
            image_path=res['image_path'] if res['image_path'] else None,
            evidence_ids=json.loads(res['evidence_ids'])
        )

    def _rrf(
        self,
        retrieved: list[list[dict]],
        k: int = 60,
    ) -> list[tuple[int, float]]:
        """
        retrieved: Retrieved results of each path. Should be sorted(defualt by search).

        Returns:
            Reranked list of pair (id, score).
        """
        rrf_map = {}

        for path in retrieved:
            if not path:
                continue

            # Sort by score descending to get ranks
            # sorted_path = sorted(path, key=lambda x: x['distance'])

            for rank, item in enumerate(path, start=1):
                if item['id'] not in rrf_map:
                    rrf_map[item['id']] = 0.0
                rrf_map[item['id']] += 1.0 / (k + rank)

        res = [
            (id, score)
            for id, score in rrf_map.items()
        ]
        return sorted(res, key=lambda x: x[1], reverse=True)

    def _embed_text(self, text: str):
        """Generate text embedding"""
        return self.text_embedder.embed_query(text)

    def _embed_image(self, image_path: str):
        """
        Generate visual embedding
        """
        return self.multimodal_embedder.encode_image(image_path)

    def _embed_text_for_cross_modal(self, text: str):
        """
        Generate CLIP text embedding for cross-modal matching
        """
        return self.multimodal_embedder.embed_text(text)
